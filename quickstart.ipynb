{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# RecommendKit Quickstart Guide\n",
        "\n",
        "This notebook demonstrates how to use RecommendKit to build a recommendation system from scratch.\n",
        "\n",
        "## What You'll Learn\n",
        "1. Loading and exploring recommendation data\n",
        "2. Understanding user and item features\n",
        "3. Configuring the model with SimpleFusion\n",
        "4. Training a recommendation model\n",
        "5. Running inference to get recommendations\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup and Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… All imports successful!\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import os\n",
        "import json\n",
        "import torch\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "# Add project root to path\n",
        "project_root = Path.cwd()\n",
        "sys.path.append(str(project_root))\n",
        "\n",
        "# Import RecommendKit components\n",
        "from input_processor import Inputs\n",
        "from trainer.pipeline_builder import RecommendationPipeline, save_complete_model\n",
        "from trainer.data_loader import create_data_loaders, load_interactions_from_input\n",
        "from trainer.trainer import train_model\n",
        "\n",
        "print(\"âœ… All imports successful!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Load and Explore Data\n",
        "\n",
        "RecommendKit uses a simple JSON format for data. Let's load and explore the dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ”„ Loading data...\n",
            "Loaded 13600 interactions\n",
            "âœ… Data loaded successfully!\n",
            "\n",
            "ğŸ“Š Dataset Statistics:\n",
            "   Users: 1000\n",
            "   Items: 100\n"
          ]
        }
      ],
      "source": [
        "# Load data\n",
        "data_path = \"datasets/synthetic/correlated_dataset.json\"\n",
        "\n",
        "print(\"ğŸ”„ Loading data...\")\n",
        "inputs = Inputs()\n",
        "inputs.configure_validators(image_check_files=False)  # Skip image file validation for demo\n",
        "result = inputs.load_from_json(data_path)\n",
        "\n",
        "if not result.is_valid:\n",
        "    print(\"âŒ Data loading errors:\")\n",
        "    for error in result.errors:\n",
        "        print(f\"  - {error}\")\n",
        "else:\n",
        "    print(\"âœ… Data loaded successfully!\")\n",
        "    \n",
        "    # Get data\n",
        "    user_data = inputs.get_user_data()\n",
        "    item_data = inputs.get_item_data()\n",
        "    \n",
        "    print(f\"\\nğŸ“Š Dataset Statistics:\")\n",
        "    print(f\"   Users: {len(user_data)}\")\n",
        "    print(f\"   Items: {len(item_data)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.1 Explore User Features\n",
        "\n",
        "User features represent characteristics of users in the system. Let's examine a sample user:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ‘¤ Sample User Features:\n",
            "   User ID: 1\n",
            "\n",
            "   Categorical Features (discrete values):\n",
            "     - occupation: scientist\n",
            "     - location: Canada\n",
            "\n",
            "   Continuous Features (numeric values):\n",
            "     - age: 41.0\n",
            "     - salary: 121172.52\n",
            "\n",
            "   Temporal Features (sequential data):\n",
            "     - Previous liked items: 14 items\n",
            "     - Sample items: [83, 84, 85, 86, 87]...\n",
            "\n",
            "============================================================\n",
            "\n",
            "ğŸ’¡ Feature Types Explained:\n",
            "   â€¢ Categorical: Discrete values (e.g., occupation, location)\n",
            "   â€¢ Continuous: Numeric values (e.g., age, salary)\n",
            "   â€¢ Temporal: Sequential interaction history\n"
          ]
        }
      ],
      "source": [
        "# Display first user as example\n",
        "sample_user = user_data[0]\n",
        "\n",
        "print(\"ğŸ‘¤ Sample User Features:\")\n",
        "print(f\"   User ID: {sample_user['user_id']}\")\n",
        "print(f\"\\n   Categorical Features (discrete values):\")\n",
        "for key, value in sample_user.get('categorical', {}).items():\n",
        "    print(f\"     - {key}: {value}\")\n",
        "    \n",
        "print(f\"\\n   Continuous Features (numeric values):\")\n",
        "for key, value in sample_user.get('continuous', {}).items():\n",
        "    print(f\"     - {key}: {value}\")\n",
        "    \n",
        "print(f\"\\n   Temporal Features (sequential data):\")\n",
        "if 'temporal' in sample_user:\n",
        "    prev_items = sample_user['temporal'].get('previous_liked_items', [])\n",
        "    print(f\"     - Previous liked items: {len(prev_items)} items\")\n",
        "    print(f\"     - Sample items: {prev_items[:5]}...\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"\\nğŸ’¡ Feature Types Explained:\")\n",
        "print(\"   â€¢ Categorical: Discrete values (e.g., occupation, location)\")\n",
        "print(\"   â€¢ Continuous: Numeric values (e.g., age, salary)\")\n",
        "print(\"   â€¢ Temporal: Sequential interaction history\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.2 Explore Item Features\n",
        "\n",
        "Item features represent characteristics of items/products. Let's examine a sample item:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ“¦ Sample Item Features:\n",
            "   Item ID: 1\n",
            "\n",
            "   Categorical Features:\n",
            "     - category: tech\n",
            "\n",
            "   Continuous Features:\n",
            "     - price: 1350.97\n",
            "\n",
            "   Text Features:\n",
            "     - name: Laptop\n",
            "     - description: High-quality Laptop for professionals and enthusiasts\n",
            "\n",
            "============================================================\n",
            "\n",
            "ğŸ’¡ Item Feature Types:\n",
            "   â€¢ Categorical: Item categories, brands, etc.\n",
            "   â€¢ Continuous: Price, rating, etc.\n",
            "   â€¢ Text: Name, description, etc.\n"
          ]
        }
      ],
      "source": [
        "# Display first item as example\n",
        "sample_item = item_data[0]\n",
        "\n",
        "print(\"ğŸ“¦ Sample Item Features:\")\n",
        "print(f\"   Item ID: {sample_item['item_id']}\")\n",
        "print(f\"\\n   Categorical Features:\")\n",
        "for key, value in sample_item.get('categorical', {}).items():\n",
        "    print(f\"     - {key}: {value}\")\n",
        "    \n",
        "print(f\"\\n   Continuous Features:\")\n",
        "for key, value in sample_item.get('continuous', {}).items():\n",
        "    print(f\"     - {key}: {value}\")\n",
        "    \n",
        "print(f\"\\n   Text Features:\")\n",
        "for key, value in sample_item.get('text', {}).items():\n",
        "    print(f\"     - {key}: {value}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"\\nğŸ’¡ Item Feature Types:\")\n",
        "print(\"   â€¢ Categorical: Item categories, brands, etc.\")\n",
        "print(\"   â€¢ Continuous: Price, rating, etc.\")\n",
        "print(\"   â€¢ Text: Name, description, etc.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Configure the Model\n",
        "\n",
        "RecommendKit uses JSON configuration files to define model architecture. Let's load and explain the SimpleFusion configuration:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âš™ï¸  Model Configuration (SimpleFusion):\n",
            "\n",
            "============================================================\n",
            "\n",
            "ğŸ¯ Core Settings:\n",
            "   â€¢ Embedding Dimension: 64\n",
            "   â€¢ Loss Type: bce\n",
            "\n",
            "ğŸ”§ Fusion Architecture:\n",
            "   â€¢ User SimpleFusion: True\n",
            "   â€¢ Item SimpleFusion: True\n",
            "   â€¢ Interaction SimpleFusion: True\n",
            "\n",
            "   ğŸ’¡ SimpleFusion: Fast concatenation + MLP approach (no transformers)\n",
            "\n",
            "ğŸ“š Encoder Configurations:\n",
            "   â€¢ Text Encoder: glove-wiki-gigaword-50\n",
            "   â€¢ Categorical Encoder: Hash-based embeddings\n",
            "   â€¢ Continuous Encoder: MLP with normalization\n",
            "   â€¢ Temporal Encoder: LSTM for sequential data\n",
            "\n",
            "ğŸ“ Training Settings:\n",
            "   â€¢ Epochs: 25\n",
            "   â€¢ Batch Size: 32\n",
            "   â€¢ Learning Rate: 0.001\n",
            "   â€¢ Train/Val Split: 0.8\n"
          ]
        }
      ],
      "source": [
        "# Load configuration\n",
        "config_path = \"configs/correlated_dataset_config.json\"\n",
        "\n",
        "with open(config_path, 'r') as f:\n",
        "    config = json.load(f)\n",
        "\n",
        "print(\"âš™ï¸  Model Configuration (SimpleFusion):\")\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"\\nğŸ¯ Core Settings:\")\n",
        "print(f\"   â€¢ Embedding Dimension: {config['embedding_dim']}\")\n",
        "print(f\"   â€¢ Loss Type: {config['loss_type']}\")\n",
        "\n",
        "print(\"\\nğŸ”§ Fusion Architecture:\")\n",
        "print(f\"   â€¢ User SimpleFusion: {config['user_use_simple_fusion']}\")\n",
        "print(f\"   â€¢ Item SimpleFusion: {config['item_use_simple_fusion']}\")\n",
        "print(f\"   â€¢ Interaction SimpleFusion: {config['interaction_use_simple_fusion']}\")\n",
        "print(\"\\n   ğŸ’¡ SimpleFusion: Fast concatenation + MLP approach (no transformers)\")\n",
        "\n",
        "print(\"\\nğŸ“š Encoder Configurations:\")\n",
        "print(f\"   â€¢ Text Encoder: {config['text_encoder_config']['model_name']}\")\n",
        "print(f\"   â€¢ Categorical Encoder: Hash-based embeddings\")\n",
        "print(f\"   â€¢ Continuous Encoder: MLP with normalization\")\n",
        "print(f\"   â€¢ Temporal Encoder: LSTM for sequential data\")\n",
        "\n",
        "print(\"\\nğŸ“ Training Settings:\")\n",
        "print(f\"   â€¢ Epochs: {config['num_epochs']}\")\n",
        "print(f\"   â€¢ Batch Size: {config['batch_size']}\")\n",
        "print(f\"   â€¢ Learning Rate: {config['learning_rate']}\")\n",
        "print(f\"   â€¢ Train/Val Split: {config['train_split']}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Create the Model\n",
        "\n",
        "Now let's create the recommendation model using our configuration:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting gensim\n",
            "  Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /home/darshil/Desktop/env_rec/lib/python3.12/site-packages (from gensim) (2.3.3)\n",
            "Collecting scipy>=1.7.0 (from gensim)\n",
            "  Using cached scipy-1.16.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (62 kB)\n",
            "Collecting smart_open>=1.8.1 (from gensim)\n",
            "  Downloading smart_open-7.5.0-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting wrapt (from smart_open>=1.8.1->gensim)\n",
            "  Downloading wrapt-2.0.1-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (9.0 kB)\n",
            "Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (27.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m27.9/27.9 MB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hUsing cached scipy-1.16.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (35.7 MB)\n",
            "Downloading smart_open-7.5.0-py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m63.9/63.9 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wrapt-2.0.1-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (121 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m121.5/121.5 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: wrapt, scipy, smart_open, gensim\n",
            "Successfully installed gensim-4.4.0 scipy-1.16.3 smart_open-7.5.0 wrapt-2.0.1\n"
          ]
        }
      ],
      "source": [
        "!python3 -m pip install --break-system-packages gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ”„ Creating model...\n",
            "Loading Word2Vec model: glove-wiki-gigaword-50\n",
            "Successfully loaded Word2Vec model with 50 dimensions\n",
            "Temporal encoder: Creating with item lookup enabled\n",
            "âœ… Model created successfully!\n",
            "   Total parameters: 975,361\n",
            "   Trainable parameters: 975,361\n",
            "   Device: cpu\n"
          ]
        }
      ],
      "source": [
        "print(\"ğŸ”„ Creating model...\")\n",
        "\n",
        "model = RecommendationPipeline(\n",
        "    embedding_dim=config.get('embedding_dim', 64),\n",
        "    loss_type=config.get('loss_type', 'bce'),\n",
        "    \n",
        "    # User tower configuration\n",
        "    user_num_attention_layers=config.get('user_num_attention_layers', 0),\n",
        "    user_num_heads=config.get('user_num_heads', 1),\n",
        "    user_dropout=config.get('user_dropout', 0.0),\n",
        "    user_use_cls_token=config.get('user_use_cls_token', False),\n",
        "    user_use_layer_norm=config.get('user_use_layer_norm', False),\n",
        "    user_use_simple_fusion=config.get('user_use_simple_fusion', True),\n",
        "    \n",
        "    # Item tower configuration\n",
        "    item_num_attention_layers=config.get('item_num_attention_layers', 0),\n",
        "    item_num_heads=config.get('item_num_heads', 1),\n",
        "    item_dropout=config.get('item_dropout', 0.0),\n",
        "    item_use_simple_fusion=config.get('item_use_simple_fusion', True),\n",
        "    \n",
        "    # Interaction modeling configuration\n",
        "    interaction_num_attention_layers=config.get('interaction_num_attention_layers', 0),\n",
        "    interaction_num_heads=config.get('interaction_num_heads', 1),\n",
        "    interaction_dropout=config.get('interaction_dropout', 0.0),\n",
        "    interaction_use_simple_fusion=config.get('interaction_use_simple_fusion', True),\n",
        "    \n",
        "    # Classifier configuration\n",
        "    classifier_hidden_dims=config.get('classifier_hidden_dims', [64]),\n",
        "    classifier_dropout=config.get('classifier_dropout', 0.0),\n",
        "    \n",
        "    # Encoder configurations\n",
        "    image_encoder_config=config.get('image_encoder_config'),\n",
        "    text_encoder_config=config.get('text_encoder_config'),\n",
        "    categorical_encoder_config=config.get('categorical_encoder_config'),\n",
        "    continuous_encoder_config=config.get('continuous_encoder_config'),\n",
        "    temporal_encoder_config=config.get('temporal_encoder_config'),\n",
        "    \n",
        "    # Item data for temporal encoder\n",
        "    item_data=item_data\n",
        ")\n",
        "\n",
        "# Count parameters\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f\"âœ… Model created successfully!\")\n",
        "print(f\"   Total parameters: {total_params:,}\")\n",
        "print(f\"   Trainable parameters: {trainable_params:,}\")\n",
        "print(f\"   Device: {'cuda' if torch.cuda.is_available() else 'cpu'}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Prepare Data Loaders\n",
        "\n",
        "We need to create data loaders for training. RecommendKit automatically handles positive/negative sampling:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ”„ Loading interactions...\n",
            "Loaded 13600 real interactions from input data\n",
            "Positive interactions: 13600\n",
            "Negative interactions: 0\n",
            "Positive ratio: 1.000\n",
            "âœ… Loaded 13600 interactions\n",
            "\n",
            "ğŸ”„ Creating data loaders...\n",
            "Split interactions: 10880 train, 2720 validation\n",
            "Created dataset with 10880 positive and 10880 negative samples\n",
            "Created dataset with 2720 positive and 2720 negative samples\n",
            "âœ… Data loaders created!\n",
            "   Train batches: 680\n",
            "   Validation batches: 170\n",
            "\n",
            "ğŸ’¡ Negative sampling: For each positive interaction, we generate\n",
            "   1.0 negative samples (items user hasn't interacted with)\n"
          ]
        }
      ],
      "source": [
        "print(\"ğŸ”„ Loading interactions...\")\n",
        "interactions = load_interactions_from_input(inputs)\n",
        "print(f\"âœ… Loaded {len(interactions)} interactions\")\n",
        "\n",
        "print(\"\\nğŸ”„ Creating data loaders...\")\n",
        "train_loader, val_loader = create_data_loaders(\n",
        "    inputs=inputs,\n",
        "    interactions=interactions,\n",
        "    train_split=config.get('train_split', 0.8),\n",
        "    batch_size=config.get('batch_size', 32),\n",
        "    negative_sampling_ratio=config.get('negative_sampling_ratio', 1.0),\n",
        "    seed=config.get('seed', 42)\n",
        ")\n",
        "\n",
        "print(f\"âœ… Data loaders created!\")\n",
        "print(f\"   Train batches: {len(train_loader)}\")\n",
        "print(f\"   Validation batches: {len(val_loader)}\")\n",
        "print(f\"\\nğŸ’¡ Negative sampling: For each positive interaction, we generate\")\n",
        "print(f\"   {config.get('negative_sampling_ratio', 1.0)} negative samples (items user hasn't interacted with)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Train the Model\n",
        "\n",
        "Now let's train the model. We'll use fewer epochs for this quickstart:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸš€ Starting training for 3 epochs...\n",
            "============================================================\n",
            "Training on cpu\n",
            "Model parameters: 975,361\n",
            "Starting training for 3 epochs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                    \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 1/3 Summary (15.2m)\n",
            "  Train Loss: 0.4773, Train Acc: 0.7485\n",
            "  Val Loss: 0.3318, Val Acc: 0.8713\n",
            "  LR: 0.000750\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                    \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 2/3 Summary (28.6m)\n",
            "  Train Loss: 0.2259, Train Acc: 0.9196\n",
            "  Val Loss: 0.2635, Val Acc: 0.9017\n",
            "  LR: 0.000250\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                    "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 3/3 Summary (42.6m)\n",
            "  Train Loss: 0.1827, Train Acc: 0.9349\n",
            "  Val Loss: 0.2530, Val Acc: 0.9114\n",
            "  LR: 0.000000\n",
            "\n",
            "\n",
            "Training completed in 42.6 minutes\n",
            "\n",
            "============================================================\n",
            "âœ… Training completed!\n",
            "\n",
            "ğŸ“Š Final Results:\n",
            "   Train Loss: 0.1827\n",
            "   Train Accuracy: 0.9349\n",
            "   Val Loss: 0.2530\n",
            "   Val Accuracy: 0.9114\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r"
          ]
        }
      ],
      "source": [
        "# Use fewer epochs for quickstart\n",
        "num_epochs = 3  # Reduced from config for faster demo\n",
        "\n",
        "print(f\"ğŸš€ Starting training for {num_epochs} epochs...\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "history = train_model(\n",
        "    model=model,\n",
        "    train_loader=train_loader,\n",
        "    val_loader=val_loader,\n",
        "    num_epochs=num_epochs,\n",
        "    learning_rate=config.get('learning_rate', 0.001),\n",
        "    optimizer_type=config.get('optimizer_type', 'adam'),\n",
        "    scheduler_type=config.get('scheduler_type', 'cosine'),\n",
        "    print_every=config.get('print_every', 1)\n",
        ")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"âœ… Training completed!\")\n",
        "print(f\"\\nğŸ“Š Final Results:\")\n",
        "print(f\"   Train Loss: {history['train_losses'][-1]:.4f}\")\n",
        "print(f\"   Train Accuracy: {history['train_accuracies'][-1]:.4f}\")\n",
        "if history['val_losses']:\n",
        "    print(f\"   Val Loss: {history['val_losses'][-1]:.4f}\")\n",
        "    print(f\"   Val Accuracy: {history['val_accuracies'][-1]:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Save the Model\n",
        "\n",
        "Let's save the trained model for later use:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ’¾ Saving model to models/quickstart_model...\n",
            "âœ… Complete model saved to models/\n",
            "   Main model: models/quickstart_model.pt\n",
            "   Config: models/quickstart_model_config.json\n",
            "   Manifest: models/quickstart_model_manifest.json\n",
            "   Components: 8 individual state dicts\n",
            "âœ… Model saved successfully!\n"
          ]
        }
      ],
      "source": [
        "save_dir = \"models\"\n",
        "model_name = \"quickstart_model\"\n",
        "\n",
        "print(f\"ğŸ’¾ Saving model to {save_dir}/{model_name}...\")\n",
        "save_complete_model(model, save_dir, model_name)\n",
        "print(\"âœ… Model saved successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Run Inference\n",
        "\n",
        "Now let's use the trained model to generate recommendations for a user:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ‘¤ Generating recommendations for User 2\n",
            "   Occupation: lawyer\n",
            "   Location: India\n",
            "   Age: 51.0\n",
            "\n",
            "ğŸ”„ Computing recommendations...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ¯ Top 10 Recommendations for User 2\n",
            "============================================================\n",
            "\n",
            "1. Business Suit\n",
            "   Score: 0.9698\n",
            "   Item ID: 59\n",
            "   Categories: category: business\n",
            "   Features: price: 214.38\n",
            "\n",
            "2. Office Chair\n",
            "   Score: 0.9689\n",
            "   Item ID: 66\n",
            "   Categories: category: business\n",
            "   Features: price: 643.2\n",
            "\n",
            "3. Briefcase\n",
            "   Score: 0.9688\n",
            "   Item ID: 60\n",
            "   Categories: category: business\n",
            "   Features: price: 365.62\n",
            "\n",
            "4. Tie\n",
            "   Score: 0.9685\n",
            "   Item ID: 62\n",
            "   Categories: category: business\n",
            "   Features: price: 548.0\n",
            "\n",
            "5. Document Organizer\n",
            "   Score: 0.9680\n",
            "   Item ID: 63\n",
            "   Categories: category: business\n",
            "   Features: price: 489.86\n",
            "\n",
            "6. Desk Lamp\n",
            "   Score: 0.9678\n",
            "   Item ID: 65\n",
            "   Categories: category: business\n",
            "   Features: price: 690.0\n",
            "\n",
            "7. Leather Shoes\n",
            "   Score: 0.9676\n",
            "   Item ID: 61\n",
            "   Categories: category: business\n",
            "   Features: price: 792.67\n",
            "\n",
            "8. File Cabinet\n",
            "   Score: 0.9674\n",
            "   Item ID: 64\n",
            "   Categories: category: business\n",
            "   Features: price: 579.23\n",
            "\n",
            "9. Sunglasses\n",
            "   Score: 0.7941\n",
            "   Item ID: 95\n",
            "   Categories: category: weather_hot\n",
            "   Features: price: 31.43\n",
            "\n",
            "10. Sunscreen\n",
            "   Score: 0.7939\n",
            "   Item ID: 96\n",
            "   Categories: category: weather_hot\n",
            "   Features: price: 88.69\n"
          ]
        }
      ],
      "source": [
        "# Set model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Select a user for recommendations\n",
        "target_user_id = 2\n",
        "k = 10  # Number of recommendations\n",
        "\n",
        "# Find user data\n",
        "target_user = None\n",
        "for user in user_data:\n",
        "    if user['user_id'] == target_user_id:\n",
        "        target_user = user\n",
        "        break\n",
        "\n",
        "if target_user is None:\n",
        "    print(f\"âŒ User {target_user_id} not found!\")\n",
        "else:\n",
        "    print(f\"ğŸ‘¤ Generating recommendations for User {target_user_id}\")\n",
        "    print(f\"   Occupation: {target_user.get('categorical', {}).get('occupation', 'N/A')}\")\n",
        "    print(f\"   Location: {target_user.get('categorical', {}).get('location', 'N/A')}\")\n",
        "    print(f\"   Age: {target_user.get('continuous', {}).get('age', 'N/A')}\")\n",
        "    print(\"\\nğŸ”„ Computing recommendations...\")\n",
        "    \n",
        "    # Prepare user data for model\n",
        "    user_features = {\n",
        "        'categorical': target_user.get('categorical', {}),\n",
        "        'continuous': target_user.get('continuous', {}),\n",
        "        'temporal': target_user.get('temporal', {})\n",
        "    }\n",
        "    \n",
        "    # Compute similarities with all items\n",
        "    similarities = []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for item in item_data:\n",
        "            item_features = {\n",
        "                'categorical': item.get('categorical', {}),\n",
        "                'continuous': item.get('continuous', {}),\n",
        "                'text': item.get('text', {})\n",
        "            }\n",
        "            \n",
        "            # Get prediction score\n",
        "            logits = model(\n",
        "                user_data={k: v for k, v in user_features.items() if v},\n",
        "                item_data={k: v for k, v in item_features.items() if v}\n",
        "            )\n",
        "            \n",
        "            # Convert to probability\n",
        "            score = torch.sigmoid(logits).item()\n",
        "            \n",
        "            similarities.append({\n",
        "                'item_id': item['item_id'],\n",
        "                'item': item,\n",
        "                'score': score\n",
        "            })\n",
        "    \n",
        "    # Sort by score and get top-k\n",
        "    similarities.sort(key=lambda x: x['score'], reverse=True)\n",
        "    top_k = similarities[:k]\n",
        "    \n",
        "    print(f\"\\nğŸ¯ Top {k} Recommendations for User {target_user_id}\")\n",
        "    print(\"=\"*60)\n",
        "    \n",
        "    for i, rec in enumerate(top_k, 1):\n",
        "        item = rec['item']\n",
        "        item_name = item.get('text', {}).get('name', f\"Item {item['item_id']}\")\n",
        "        print(f\"\\n{i}. {item_name}\")\n",
        "        print(f\"   Score: {rec['score']:.4f}\")\n",
        "        print(f\"   Item ID: {item['item_id']}\")\n",
        "        \n",
        "        if 'categorical' in item and item['categorical']:\n",
        "            cat_info = \", \".join([f\"{k}: {v}\" for k, v in item['categorical'].items()])\n",
        "            print(f\"   Categories: {cat_info}\")\n",
        "        \n",
        "        if 'continuous' in item and item['continuous']:\n",
        "            cont_info = \", \".join([f\"{k}: {v}\" for k, v in item['continuous'].items()])\n",
        "            print(f\"   Features: {cont_info}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Next Steps\n",
        "\n",
        "Congratulations! You've successfully:\n",
        "1. âœ… Loaded and explored recommendation data\n",
        "2. âœ… Configured a SimpleFusion model\n",
        "3. âœ… Trained a recommendation model\n",
        "4. âœ… Generated personalized recommendations\n",
        "\n",
        "### What's Next?\n",
        "\n",
        "- **Try Attention-Based Fusion**: Use `correlated_dataset_attention_config.json` for transformer-based feature fusion\n",
        "- **Experiment with Configurations**: Adjust embedding dimensions, hidden layers, and other hyperparameters\n",
        "- **Use Your Own Data**: Format your data in the JSON structure shown above\n",
        "- **Production Deployment**: Use the saved model with `inference.py` for production inference\n",
        "\n",
        "### Learn More\n",
        "\n",
        "Check out the README.md for:\n",
        "- Detailed architecture explanations\n",
        "- Advanced customization options\n",
        "- Integration examples\n",
        "\n",
        "Happy recommending! ğŸš€\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "env_rec",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
