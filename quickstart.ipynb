{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# RecommendKit Quickstart Guide\n",
        "\n",
        "This notebook demonstrates how to use RecommendKit to build a recommendation system from scratch using simple command-line tools.\n",
        "\n",
        "## What You'll Learn\n",
        "1. Generating synthetic data for testing\n",
        "2. Understanding configuration files\n",
        "3. Training a model using command-line tools\n",
        "4. Running inference to get recommendations\n",
        "5. Exploring the trained model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Generate Synthetic Dataset\n",
        "\n",
        "Since we don't upload datasets to GitHub, let's generate a synthetic dataset for testing. This script creates a realistic dataset with perfect correlations between user attributes and item preferences.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ¯ Generating correlated dataset with 1000 users and ~100 items...\n",
            "âœ… Generated 100 items\n",
            "âœ… Generated 1000 users\n",
            "âœ… Generated 13600 interactions\n",
            "\n",
            "ğŸ’¾ Dataset saved to: correlated_dataset.json\n",
            "\n",
            "============================================================\n",
            "ğŸ“Š DATASET STATISTICS\n",
            "============================================================\n",
            "\n",
            "ğŸ”¢ Counts:\n",
            "   Users: 1000\n",
            "   Items: 100\n",
            "   Interactions: 13600\n",
            "\n",
            "ğŸ‘” Occupation Distribution:\n",
            "   artist: 100 users\n",
            "   chef: 100 users\n",
            "   doctor: 100 users\n",
            "   driver: 100 users\n",
            "   lawyer: 100 users\n",
            "   mechanical_engineer: 100 users\n",
            "   nurse: 100 users\n",
            "   scientist: 100 users\n",
            "   software_engineer: 100 users\n",
            "   teacher: 100 users\n",
            "\n",
            "ğŸŒ Location Distribution:\n",
            "   Australia: 200 users\n",
            "   Canada: 200 users\n",
            "   India: 200 users\n",
            "   UK: 200 users\n",
            "   USA: 200 users\n",
            "\n",
            "ğŸ“¦ Item Category Distribution:\n",
            "   art: 8 items\n",
            "   automotive: 8 items\n",
            "   business: 8 items\n",
            "   educational: 8 items\n",
            "   healthcare: 8 items\n",
            "   kitchen: 10 items\n",
            "   lab: 6 items\n",
            "   medical_equipment: 10 items\n",
            "   tech: 12 items\n",
            "   tools: 10 items\n",
            "   weather_cold: 4 items\n",
            "   weather_hot: 4 items\n",
            "   weather_rain: 4 items\n",
            "\n",
            "ğŸ’¬ Interaction Statistics:\n",
            "   Total interactions: 13600\n",
            "   All positive (negatives will be sampled by data loader)\n",
            "   Avg interactions per user: 13.6\n",
            "\n",
            "ğŸ‘¤ Sample User Analysis:\n",
            "\n",
            "   User 1:\n",
            "      Occupation: scientist\n",
            "      Location: Canada\n",
            "      Age: 41\n",
            "      Salary: $121,173\n",
            "      Interacted items: 14\n",
            "      Item categories: lab, weather_cold, weather_rain\n",
            "\n",
            "   User 251:\n",
            "      Occupation: driver\n",
            "      Location: India\n",
            "      Age: 69\n",
            "      Salary: $86,098\n",
            "      Interacted items: 12\n",
            "      Item categories: automotive, weather_hot\n",
            "\n",
            "   User 501:\n",
            "      Occupation: lawyer\n",
            "      Location: India\n",
            "      Age: 34\n",
            "      Salary: $131,964\n",
            "      Interacted items: 12\n",
            "      Item categories: business, weather_hot\n",
            "\n",
            "============================================================\n",
            "\n",
            "âœ… Dataset generation complete!\n",
            "âœ… Synthetic dataset generated!\n"
          ]
        }
      ],
      "source": [
        "# Generate synthetic dataset\n",
        "!cd datasets/synthetic && python3 generate_correlated_dataset.py --num_users 1000 --num_items 100 --output correlated_dataset.json\n",
        "\n",
        "print(\"âœ… Synthetic dataset generated!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Explore the Configuration File\n",
        "\n",
        "RecommendKit uses JSON configuration files to define model architecture. This makes training incredibly simple - just point to a config file! Let's examine the SimpleFusion configuration:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âš™ï¸  SimpleFusion Configuration File\n",
            "============================================================\n",
            "{\n",
            "  \"embedding_dim\": 64,\n",
            "  \"loss_type\": \"bce\",\n",
            "  \"user_num_attention_layers\": 0,\n",
            "  \"user_num_heads\": 1,\n",
            "  \"user_dropout\": 0.0,\n",
            "  \"user_use_cls_token\": false,\n",
            "  \"user_use_layer_norm\": false,\n",
            "  \"user_use_simple_fusion\": true,\n",
            "  \"item_num_attention_layers\": 0,\n",
            "  \"item_num_heads\": 1,\n",
            "  \"item_dropout\": 0.0,\n",
            "  \"item_use_simple_fusion\": true,\n",
            "  \"interaction_num_attention_layers\": 0,\n",
            "  \"interaction_num_heads\": 1,\n",
            "  \"interaction_dropout\": 0.0,\n",
            "  \"interaction_use_simple_fusion\": true,\n",
            "  \"classifier_hidden_dims\": [\n",
            "    64\n",
            "  ],\n",
            "  \"classifier_dropout\": 0.0,\n",
            "  \"text_encoder_config\": {\n",
            "    \"model_name\": \"glove-wiki-gigaword-50\",\n",
            "    \"aggregation_strategy\": \"mean\",\n",
            "    \"embedding_dim\": 64,\n",
            "    \"num_text_fields\": 2\n",
            "  },\n",
            "  \"categorical_encoder_config\": {\n",
            "    \"aggregation_strategy\": \"separate_concat\",\n",
            "    \"hash_vocab_size\": 4096,\n",
            "    \"embedding_dim\": 64,\n",
            "    \"num_categorical_fields\": 1,\n",
            "    \"mlp_hidden_dims\": []\n",
            "  },\n",
            "  \"continuous_encoder_config\": {\n",
            "    \"embedding_dim\": 64,\n",
            "    \"hidden_dims\": [\n",
            "      64\n",
            "    ],\n",
            "    \"dropout\": 0.0,\n",
            "    \"normalize\": true\n",
            "  },\n",
            "  \"image_encoder_config\": null,\n",
            "  \"temporal_encoder_config\": {\n",
            "    \"enable_item_lookup\": true,\n",
            "    \"aggregation_strategy\": \"mean_pooling\",\n",
            "    \"output_dim\": 64\n",
            "  },\n",
            "  \"train_split\": 0.8,\n",
            "  \"batch_size\": 32,\n",
            "  \"negative_sampling_ratio\": 1.0,\n",
            "  \"seed\": 42,\n",
            "  \"num_epochs\": 3,\n",
            "  \"learning_rate\": 0.001,\n",
            "  \"optimizer_type\": \"adam\",\n",
            "  \"scheduler_type\": \"cosine\",\n",
            "  \"print_every\": 1,\n",
            "  \"model_name\": \"simple_baseline_model\"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "# Load and display the configuration file\n",
        "config_path = \"configs/sample_config_simple_fusion.json\"\n",
        "\n",
        "with open(config_path, 'r') as f:\n",
        "    config = json.load(f)\n",
        "\n",
        "print(\"âš™ï¸  SimpleFusion Configuration File\")\n",
        "print(\"=\" * 60)\n",
        "print(json.dumps(config, indent=2))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Train the Model\n",
        "\n",
        "Now let's train the model using the command-line tool. It's as simple as pointing to your data and config file!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸš€ Generic Recommendation System Training\n",
            "============================================================\n",
            "ğŸ”„ Loading training configuration...\n",
            "âœ… Configuration loaded from configs/sample_config_simple_fusion.json\n",
            "ğŸ”„ Loading data...\n",
            "Loaded 13600 interactions\n",
            "âœ… Loaded 1000 users and 100 items\n",
            "ğŸ”„ Loading interactions...\n",
            "Loaded 13600 real interactions from input data\n",
            "Positive interactions: 13600\n",
            "Negative interactions: 0\n",
            "Positive ratio: 1.000\n",
            "âœ… Loaded 13600 interactions\n",
            "ğŸ”„ Creating model...\n",
            "Loading Word2Vec model: glove-wiki-gigaword-50\n",
            "Successfully loaded Word2Vec model with 50 dimensions\n",
            "Temporal encoder: Creating with item lookup enabled\n",
            "âœ… Model created with 975,361 parameters\n",
            "âœ… Using device: cpu\n",
            "ğŸ”„ Creating data loaders...\n",
            "Split interactions: 10880 train, 2040 validation, 680 test\n",
            "Created dataset with 10880 positive and 10880 negative samples\n",
            "Created dataset with 2040 positive and 2040 negative samples\n",
            "âœ… Data loaders created - Train: 680 batches, Val: 128 batches, Test: 680 interactions\n",
            "âœ… Test interactions saved to models/quickstart_model_test_interactions.json\n",
            "âœ… Training interactions saved to models/quickstart_model_train_interactions.json\n",
            "ğŸš€ Starting training...\n",
            "Training on cpu\n",
            "Model parameters: 975,361\n",
            "Starting training for 3 epochs\n",
            "âœ… Parameter count matches: 1,050,177 trainable parameters                       \n",
            "   Plus 1,347 buffers (running stats, default embeddings, etc.)\n",
            "âš ï¸  Warning: 5 trainable parameters appear uninitialized (all zeros):\n",
            "   - image_encoder.backbone.feature_extractor.1.bias\n",
            "   - image_encoder.backbone.feature_extractor.5.bias\n",
            "   - image_encoder.backbone.feature_extractor.9.bias\n",
            "   - user_continuous_encoder.mlp.1.bias\n",
            "   - item_continuous_encoder.mlp.1.bias\n",
            "âœ… Saved 92 parameters and buffers to models/quickstart_model.pt\n",
            "   Total trainable parameters: 1,050,177\n",
            "   Total buffers: 1,347\n",
            "\n",
            "ğŸ“‹ Categorical encoder MLP structure (2 keys):\n",
            "   âœ… Final projection layer found at mlp.0\n",
            "      Key: categorical_encoder.field_embeddings.field_0.mlp.0.weight\n",
            "      Shape: torch.Size([64, 64])\n",
            "âœ… Complete model saved to models/\n",
            "   Main model: models/quickstart_model.pt\n",
            "   Config: models/quickstart_model_config.json\n",
            "   Manifest: models/quickstart_model_manifest.json\n",
            "   Components: 8 individual state dicts\n",
            "âœ… New best model saved (val_loss: 0.4942)\n",
            "âœ… Parameter count matches: 1,050,177 trainable parameters\n",
            "   Plus 1,347 buffers (running stats, default embeddings, etc.)\n",
            "âš ï¸  Warning: 5 trainable parameters appear uninitialized (all zeros):\n",
            "   - image_encoder.backbone.feature_extractor.1.bias\n",
            "   - image_encoder.backbone.feature_extractor.5.bias\n",
            "   - image_encoder.backbone.feature_extractor.9.bias\n",
            "   - user_continuous_encoder.mlp.1.bias\n",
            "   - item_continuous_encoder.mlp.1.bias\n",
            "âœ… Saved 92 parameters and buffers to models/quickstart_model.pt\n",
            "   Total trainable parameters: 1,050,177\n",
            "   Total buffers: 1,347\n",
            "\n",
            "ğŸ“‹ Categorical encoder MLP structure (2 keys):\n",
            "   âœ… Final projection layer found at mlp.0\n",
            "      Key: categorical_encoder.field_embeddings.field_0.mlp.0.weight\n",
            "      Shape: torch.Size([64, 64])\n",
            "âœ… Complete model saved to models/\n",
            "   Main model: models/quickstart_model.pt\n",
            "   Config: models/quickstart_model_config.json\n",
            "   Manifest: models/quickstart_model_manifest.json\n",
            "   Components: 8 individual state dicts\n",
            "ğŸ’¾ Model saved (epoch 1/3)\n",
            "\n",
            "ğŸ“Š Epoch 1/3 Summary (13.8m)\n",
            "  Train Loss: 0.5324, Train Acc: 0.6932\n",
            "  Val Loss: 0.4942, Val Acc: 0.7910\n",
            "  LR: 0.000750\n",
            "\n",
            "âœ… Parameter count matches: 1,050,177 trainable parameters                       \n",
            "   Plus 1,347 buffers (running stats, default embeddings, etc.)\n",
            "âš ï¸  Warning: 5 trainable parameters appear uninitialized (all zeros):\n",
            "   - image_encoder.backbone.feature_extractor.1.bias\n",
            "   - image_encoder.backbone.feature_extractor.5.bias\n",
            "   - image_encoder.backbone.feature_extractor.9.bias\n",
            "   - user_continuous_encoder.mlp.1.bias\n",
            "   - item_continuous_encoder.mlp.1.bias\n",
            "âœ… Saved 92 parameters and buffers to models/quickstart_model.pt\n",
            "   Total trainable parameters: 1,050,177\n",
            "   Total buffers: 1,347\n",
            "\n",
            "ğŸ“‹ Categorical encoder MLP structure (2 keys):\n",
            "   âœ… Final projection layer found at mlp.0\n",
            "      Key: categorical_encoder.field_embeddings.field_0.mlp.0.weight\n",
            "      Shape: torch.Size([64, 64])\n",
            "âœ… Complete model saved to models/\n",
            "   Main model: models/quickstart_model.pt\n",
            "   Config: models/quickstart_model_config.json\n",
            "   Manifest: models/quickstart_model_manifest.json\n",
            "   Components: 8 individual state dicts\n",
            "âœ… New best model saved (val_loss: 0.3416)\n",
            "ğŸ’¾ Model saved (epoch 2/3)\n",
            "\n",
            "ğŸ“Š Epoch 2/3 Summary (27.4m)\n",
            "  Train Loss: 0.2975, Train Acc: 0.8800\n",
            "  Val Loss: 0.3416, Val Acc: 0.8647\n",
            "  LR: 0.000250\n",
            "\n",
            "âœ… Parameter count matches: 1,050,177 trainable parameters                       \n",
            "   Plus 1,347 buffers (running stats, default embeddings, etc.)\n",
            "âš ï¸  Warning: 5 trainable parameters appear uninitialized (all zeros):\n",
            "   - image_encoder.backbone.feature_extractor.1.bias\n",
            "   - image_encoder.backbone.feature_extractor.5.bias\n",
            "   - image_encoder.backbone.feature_extractor.9.bias\n",
            "   - user_continuous_encoder.mlp.1.bias\n",
            "   - item_continuous_encoder.mlp.1.bias\n",
            "âœ… Saved 92 parameters and buffers to models/quickstart_model.pt\n",
            "   Total trainable parameters: 1,050,177\n",
            "   Total buffers: 1,347\n",
            "\n",
            "ğŸ“‹ Categorical encoder MLP structure (2 keys):\n",
            "   âœ… Final projection layer found at mlp.0\n",
            "      Key: categorical_encoder.field_embeddings.field_0.mlp.0.weight\n",
            "      Shape: torch.Size([64, 64])\n",
            "âœ… Complete model saved to models/\n",
            "   Main model: models/quickstart_model.pt\n",
            "   Config: models/quickstart_model_config.json\n",
            "   Manifest: models/quickstart_model_manifest.json\n",
            "   Components: 8 individual state dicts\n",
            "âœ… New best model saved (val_loss: 0.3253)\n",
            "ğŸ’¾ Model saved (epoch 3/3)\n",
            "\n",
            "ğŸ“Š Epoch 3/3 Summary (42.6m)\n",
            "  Train Loss: 0.2405, Train Acc: 0.9065\n",
            "  Val Loss: 0.3253, Val Acc: 0.8689\n",
            "  LR: 0.000000\n",
            "\n",
            "\n",
            "Training completed in 42.6 minutes\n",
            "ğŸ”„ Saving complete model...\n",
            "âœ… Parameter count matches: 1,050,177 trainable parameters\n",
            "   Plus 1,347 buffers (running stats, default embeddings, etc.)\n",
            "âš ï¸  Warning: 5 trainable parameters appear uninitialized (all zeros):\n",
            "   - image_encoder.backbone.feature_extractor.1.bias\n",
            "   - image_encoder.backbone.feature_extractor.5.bias\n",
            "   - image_encoder.backbone.feature_extractor.9.bias\n",
            "   - user_continuous_encoder.mlp.1.bias\n",
            "   - item_continuous_encoder.mlp.1.bias\n",
            "âœ… Saved 92 parameters and buffers to models/quickstart_model.pt\n",
            "   Total trainable parameters: 1,050,177\n",
            "   Total buffers: 1,347\n",
            "\n",
            "ğŸ“‹ Categorical encoder MLP structure (2 keys):\n",
            "   âœ… Final projection layer found at mlp.0\n",
            "      Key: categorical_encoder.field_embeddings.field_0.mlp.0.weight\n",
            "      Shape: torch.Size([64, 64])\n",
            "âœ… Complete model saved to models/\n",
            "   Main model: models/quickstart_model.pt\n",
            "   Config: models/quickstart_model_config.json\n",
            "   Manifest: models/quickstart_model_manifest.json\n",
            "   Components: 8 individual state dicts\n",
            "ğŸ‰ Training completed successfully!\n",
            "ğŸ“ Model saved to: models/quickstart_model\n",
            "ğŸ“ History saved to: models/quickstart_model_history.json\n",
            "ğŸ“Š Final train loss: 0.2405\n",
            "ğŸ“Š Final val loss: 0.3253\n",
            "ğŸ“Š Final train accuracy: 0.9065\n",
            "ğŸ“Š Final val accuracy: 0.8689\n"
          ]
        }
      ],
      "source": [
        "# Train the model using command-line tool\n",
        "!python3 train.py \\\n",
        "  --data_path datasets/synthetic/correlated_dataset.json \\\n",
        "  --config_path configs/sample_config_simple_fusion.json \\\n",
        "  --output_dir models \\\n",
        "  --model_name quickstart_model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Evaluate Model Performance\n",
        "\n",
        "Let's evaluate the trained model on the test set to see how well it performs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ“Š Recommendation System Classification Evaluation\n",
            "============================================================\n",
            "ğŸ”„ Loading data...\n",
            "Loaded 13600 interactions\n",
            "âœ… Loaded 1000 users and 100 items\n",
            "ğŸ”„ Loading test interactions...\n",
            "âœ… Loaded 680 test interactions\n",
            "ğŸ”„ Loading model...\n",
            "âœ… Config verified - matches checkpoint structure\n",
            "ğŸ” Loading model with categorical_encoder config:\n",
            "   mlp_hidden_dims: []\n",
            "   embedding_dim: 64\n",
            "   num_categorical_fields: 1\n",
            "Loading Word2Vec model: glove-wiki-gigaword-50\n",
            "Successfully loaded Word2Vec model with 50 dimensions\n",
            "Temporal encoder: Creating with item lookup enabled\n",
            "ğŸ” Checkpoint categorical encoder MLP layers: [0]\n",
            "ğŸ” Model categorical encoder MLP layers: [0]\n",
            "âœ… Model structure verified - matches checkpoint\n",
            "âœ… Pre-initialized user_continuous_encoder MLP (input_dim=2)\n",
            "âœ… Pre-initialized item_continuous_encoder MLP (input_dim=1)\n",
            "âœ… Pre-initialized user_generator.user_fusion.projection (num_features=3)\n",
            "âœ… Pre-initialized item_generator.item_fusion.projection (num_features=3)\n",
            "âœ… Model loaded on device: cpu\n",
            "ğŸ” Encoders used: ['image', 'text', 'categorical', 'continuous', 'temporal']\n",
            "ğŸ” User fusion expects 3 features\n",
            "ğŸ” Item fusion expects 3 features\n",
            "âœ… Model loaded successfully\n",
            "ğŸš€ Running classification evaluation...\n",
            "âš ï¸  WARNING: Test set has 680 positive samples but 0 negative samples!\n",
            "   Adding negative samples for proper evaluation (ratio 1:1)...\n",
            "Created dataset with 680 positive and 680 negative samples\n",
            "ğŸ”„ Evaluating 680 test interactions...\n",
            "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 43/43 [00:25<00:00,  1.67it/s]\n",
            "\n",
            "============================================================\n",
            "ğŸ“Š Classification Evaluation Results\n",
            "============================================================\n",
            "Total samples: 1360\n",
            "Positive samples: 680\n",
            "Negative samples: 680\n",
            "\n",
            "Accuracy:  0.8610\n",
            "Precision: 0.7825\n",
            "Recall:    1.0000\n",
            "F1 Score:  0.8780\n",
            "\n",
            "Confusion Matrix:\n",
            "  True Positives:  680\n",
            "  False Positives: 189\n",
            "  True Negatives:  491\n",
            "  False Negatives: 0\n",
            "\n",
            "âœ… Results saved to classification_results.json\n",
            "\n",
            "ğŸ‰ Evaluation completed successfully!\n",
            "\n",
            "ğŸ“Š Classification Evaluation Results:\n",
            "   Total samples: 1360\n",
            "   Accuracy: 0.8610\n",
            "   Precision: 0.7825\n",
            "   Recall: 1.0000\n",
            "   F1 Score: 0.8780\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model on test set using classification metrics\n",
        "import os\n",
        "!python3 evaluation/evaluate_classification.py \\\n",
        "  --model_dir models \\\n",
        "  --model_name quickstart_model \\\n",
        "  --data_path datasets/synthetic/correlated_dataset.json \\\n",
        "  --test_interactions models/quickstart_model_test_interactions.json \\\n",
        "  --batch_size 32 \\\n",
        "  --threshold 0.5 \\\n",
        "  --output_file classification_results.json\n",
        "\n",
        "# Display the evaluation results\n",
        "if os.path.exists(\"classification_results.json\"):\n",
        "    with open(\"classification_results.json\", 'r') as f:\n",
        "        results = json.load(f)\n",
        "    \n",
        "    print(\"\\nğŸ“Š Classification Evaluation Results:\")\n",
        "    print(f\"   Total samples: {results['metrics']['num_samples']}\")\n",
        "    print(f\"   Accuracy: {results['metrics']['accuracy']:.4f}\")\n",
        "    print(f\"   Precision: {results['metrics']['precision']:.4f}\")\n",
        "    print(f\"   Recall: {results['metrics']['recall']:.4f}\")\n",
        "    print(f\"   F1 Score: {results['metrics']['f1']:.4f}\")\n",
        "    if 'auc_roc' in results['metrics']:\n",
        "        print(f\"   AUC-ROC: {results['metrics']['auc_roc']:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Run Inference\n",
        "\n",
        "Now let's use the trained model to generate recommendations. The inference script makes it easy to get recommendations for any user!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸš€ Generic Recommendation System - Inference\n",
            "============================================================\n",
            "ğŸ”„ Loading data...\n",
            "Loaded 13600 interactions\n",
            "âœ… Loaded 1000 users and 100 items\n",
            "ğŸ”„ Loading trained model...\n",
            "âœ… Config verified - matches checkpoint structure\n",
            "ğŸ” Loading model with categorical_encoder config:\n",
            "   mlp_hidden_dims: []\n",
            "   embedding_dim: 64\n",
            "   num_categorical_fields: 1\n",
            "Loading Word2Vec model: glove-wiki-gigaword-50\n",
            "Successfully loaded Word2Vec model with 50 dimensions\n",
            "Temporal encoder: Creating with item lookup enabled\n",
            "ğŸ” Checkpoint categorical encoder MLP layers: [0]\n",
            "ğŸ” Model categorical encoder MLP layers: [0]\n",
            "âœ… Model structure verified - matches checkpoint\n",
            "âœ… Pre-initialized user_continuous_encoder MLP (input_dim=2)\n",
            "âœ… Pre-initialized item_continuous_encoder MLP (input_dim=1)\n",
            "âœ… Pre-initialized user_generator.user_fusion.projection (num_features=3)\n",
            "âœ… Pre-initialized item_generator.item_fusion.projection (num_features=3)\n",
            "ğŸ” Encoders used during training: ['image', 'text', 'categorical', 'continuous', 'temporal']\n",
            "ğŸ” User fusion expects 3 features (input_dim=192)\n",
            "ğŸ” Item fusion expects 3 features (input_dim=192)\n",
            "âœ… Model loaded successfully\n",
            "   Model directory: models\n",
            "   Model name: quickstart_model\n",
            "   Embedding dimension: 64\n",
            "   Model parameters: 1,050,177\n",
            "ğŸ‘¤ Target user: 1\n",
            "\n",
            "ğŸ“‹ User Profile:\n",
            "   Categorical features:\n",
            "     - occupation: scientist\n",
            "     - location: Canada\n",
            "   Continuous features:\n",
            "     - age: 41.0\n",
            "     - salary: 121172.52\n",
            "   Temporal features:\n",
            "     - previous_liked_items: 14 items\n",
            "\n",
            "ğŸ”„ Generating 10 recommendations...\n",
            "ğŸ”„ Finding top 10 items for user...\n",
            "ğŸ” Debug: Encoded user features: ['categorical_features', 'continuous_features', 'temporal']\n",
            "   categorical_features: shape torch.Size([1, 64])\n",
            "   continuous_features: shape torch.Size([1, 64])\n",
            "   temporal: shape torch.Size([1, 64])\n",
            "ğŸ” Debug: Item features to encode: ['text', 'categorical', 'continuous']\n",
            "ğŸ” Debug: Encoded item features: ['text_features', 'categorical_features', 'continuous_features']\n",
            "   text_features: shape torch.Size([1, 64])\n",
            "   categorical_features: shape torch.Size([1, 64])\n",
            "   continuous_features: shape torch.Size([1, 64])\n",
            "\n",
            "ğŸ¯ Top 10 Recommendations\n",
            "================================================================================\n",
            " 1. Thermometer\n",
            "     Score: 0.2076\n",
            "     Item ID: 14\n",
            "     Categories: category: medical_equipment\n",
            "     Features: price: 139.48\n",
            "\n",
            " 2. Lab Gloves\n",
            "     Score: 0.1990\n",
            "     Item ID: 87\n",
            "     Categories: category: lab\n",
            "     Features: price: 498.89\n",
            "\n",
            " 3. Laptop\n",
            "     Score: 0.1914\n",
            "     Item ID: 1\n",
            "     Categories: category: tech\n",
            "     Features: price: 1350.97\n",
            "\n",
            " 4. Lab Coat\n",
            "     Score: 0.1903\n",
            "     Item ID: 83\n",
            "     Categories: category: lab\n",
            "     Features: price: 313.06\n",
            "\n",
            " 5. Desk Lamp\n",
            "     Score: 0.1829\n",
            "     Item ID: 65\n",
            "     Categories: category: business\n",
            "     Features: price: 690.0\n",
            "\n",
            " 6. Prescription Glasses\n",
            "     Score: 0.1824\n",
            "     Item ID: 22\n",
            "     Categories: category: medical_equipment\n",
            "     Features: price: 364.16\n",
            "\n",
            " 7. Microscope\n",
            "     Score: 0.1701\n",
            "     Item ID: 86\n",
            "     Categories: category: lab\n",
            "     Features: price: 148.69\n",
            "\n",
            " 8. Safety Goggles\n",
            "     Score: 0.1694\n",
            "     Item ID: 84\n",
            "     Categories: category: lab\n",
            "     Features: price: 454.02\n",
            "\n",
            " 9. Medical Gloves\n",
            "     Score: 0.1612\n",
            "     Item ID: 17\n",
            "     Categories: category: medical_equipment\n",
            "     Features: price: 149.2\n",
            "\n",
            "10. Blood Pressure Monitor\n",
            "     Score: 0.1469\n",
            "     Item ID: 15\n",
            "     Categories: category: medical_equipment\n",
            "     Features: price: 342.45\n",
            "\n",
            "ğŸ‰ Inference completed successfully!\n",
            "\n",
            "ğŸ“‹ Summary:\n",
            "   âœ… Model loaded and working\n",
            "   âœ… User embeddings generated\n",
            "   âœ… Item embeddings generated\n",
            "   âœ… Similarity computation working\n",
            "   âœ… Top-k recommendations generated\n"
          ]
        }
      ],
      "source": [
        "# Generate recommendations for a user\n",
        "# The inference script will use the first user by default, or you can specify --user_id\n",
        "!python3 inference.py \\\n",
        "  --data_path datasets/synthetic/correlated_dataset.json \\\n",
        "  --model_dir models \\\n",
        "  --model_name quickstart_model \\\n",
        "  --user_id 1 \\\n",
        "  --k 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Next Steps\n",
        "\n",
        "Congratulations! You've successfully:\n",
        "1. âœ… Generated synthetic data for testing\n",
        "2. âœ… Understood the configuration file structure\n",
        "3. âœ… Trained a model using simple command-line tools\n",
        "4. âœ… Generated recommendations using inference\n",
        "\n",
        "### What's Next?\n",
        "\n",
        "- **Try Different Configurations**: Modify `configs/sample_config_simple_fusion.json` to experiment with different settings\n",
        "- **Use Your Own Data**: Format your data in the JSON structure shown above\n",
        "- **Evaluate Your Model**: Use `evaluation/evaluate_classification.py` or `evaluation/evaluate_recommendation.py`\n",
        "- **Try Attention-Based Fusion**: Use `configs/sample_config_attention_fusion.json` for transformer-based fusion\n",
        "\n",
        "### Key Takeaways\n",
        "\n",
        "- **Training is Simple**: Just `python3 train.py --data_path X --config_path Y`\n",
        "- **Inference is Easy**: Just `python3 inference.py --data_path X --model_dir Y --model_name Z`\n",
        "- **Config-Driven**: All model settings are in JSON files - no code changes needed!\n",
        "- **Production Ready**: Saved models can be loaded and used anywhere\n",
        "\n",
        "### Learn More\n",
        "\n",
        "Check out the README.md for:\n",
        "- Detailed architecture explanations\n",
        "- Advanced customization options\n",
        "- Evaluation methods\n",
        "- Integration examples\n",
        "\n",
        "Happy recommending! ğŸš€\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "env_rec",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
